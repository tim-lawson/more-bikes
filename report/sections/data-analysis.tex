\section{Data analysis}
\label{sec:data-analysis}

\begin{table}
  \centering
  \import{data-analysis}{tab-features}
  \caption{
    A summary of the features and the target variable (\texttt{bikes}), which have been renamed to be easier to read.
    Except where indicated, the features are quantitative.
    The zero-variance columns indicate whether the feature has zero variance for the cases
    of (a) separate models for each station, and (b) a single model for all stations.
  }
  \label{tab-features}
\end{table}

The data provided for sub-task~1 is recorded at hourly intervals with $n = 54385$
instances across the 75 stations.
Some features have a natural range -- in particular, the number of available bikes at a
station is bounded by zero and its number of docks
(\cref{sec:data-analysis:feature-engineering}).
A summary of the features and the numbers of missing values for the non-temporal
quantitative features are given in \cref{tab-features,tab-features-na}.

This analysis revealed that many of the features and the target variable \texttt{bikes}
are missing for $n = 73$ instances, which were henceforth excluded.
Additionally, the `profile' features, i.e., the features derived from the numbers of
available bikes at preceding times, are not defined for the first week of October 2014
at each station.
Hence, they are missing for approximately $\frac{1}{4}$ of the instances.
The meteorological features are constant for all stations at a given timestamp.

\subsection{Feature selection}
\label{sec:data-analysis:feature-selection}

\begin{table}
  \centering
  \import{data-analysis}{tab-features-na}
  \caption{
    The numbers of missing values (n/a) of features and the target variable (\texttt{bikes}).
    Except where indicated, there are zero missing values.
  }
  \label{tab-features-na}
\end{table}

Intuitively, features that have zero variance are not informative, so I automatically
excluded them.\footnote{See \sklearn{feature\_selection}{VarianceThreshold}.} For the
two cases of sub-task~1, the zero-variance features are indicated in
\cref{tab-features}.
Notably, the \texttt{precipitation} feature is zero for all instances.

Correlations between explanatory variables can cause a regression model to make
unreliable predictions \parencite{Alin2010}.
\begin{samepage}
  I identified these by computing the Pearson correlation
  coefficients between pairs of quantitative features (\cref{fig-pearson}), which
  yielded the following observations:
  \begin{itemize}
    \item \texttt{\bikesavgfull} and \texttt{\bikesavgshort} are perfectly correlated ($r = 1.00$).
    \item \texttt{\bikeshdiffavgfull} and \texttt{\bikeshdiffavgshort} are perfectly correlated ($r  = 1.00$).
    \item \texttt{\windspeedmax} and \texttt{\windspeedavg} are highly correlated ($r = 0.96$).
  \end{itemize}
\end{samepage}
Hence, for sub-task~1, the second of each of these pairs of features was also excluded.
For sub-task~2, the `profile' features were retained because they are inputs to the
pre-trained linear models (\cref{sub-task-2:tab-features-rlm}).

\begin{figure}
  \centering
  \import{data-analysis}{fig-pearson}
  \caption{
    The Pearson correlation coefficients between pairs of the quantitative features and
    the target variable (\texttt{bikes}).
    The ordering follows \cref{tab-features}.
    Features that have zero variance for the case of (a) separate models for each station
    are excluded (\cref{tab-features}).
    The \texttt{timestamp} feature is also excluded because it is naturally correlated with
    the other temporal features.
  }
  \label{fig-pearson}
\end{figure}

\subsection{Feature engineering}
\label{sec:data-analysis:feature-engineering}

For sub-task~1, the bounds on the number of available bikes at each station were
enforced by predicting the \emph{fraction} of bikes, i.e., the number of bikes divided
by the number of docks.
I implemented this by extending the \texttt{TransformedTargetRegressor} meta-estimator
to allow data-dependent transformations of the target variable.\footnote{See
  \sklearn{compose}{TransformedTargetRegressor}.
}
Another potential transformation of the target variable would have been to predict the
\emph{change} in the number of available bikes, but I did not explore this option.

\begin{figure}[!ht]
  \centering
  \import{data-analysis}{fig-weekday}
  \caption{
    The average fraction of available bikes at each hour of the day, separated by the day of the week.
    In the top chart, the data is limited to the month of October 2014 for the 75 stations
    to predict.
    In the bottom chart, the data from the first ten stations is also included
    (\cref{sec:task-description}).
  }
  \label{fig-weekday}
\end{figure}

Initially, I investigated introducing derived temporal features, e.g., by discretizing
the hour of the day into intervals.
However, as shown in \cref{fig-weekday}, the average fraction of available bikes
throughout the day differs substantially between the data from the 75 stations for
October 2014 and the data from the first ten stations between June 2012 and October
2014 (\cref{sec:task-description}).
Hence, I considered that a feature of this kind would be unlikely to generalize well to
the test data.
Additionally, because I chose to investigate tree models
(\cref{sec:sub-task-1:model-classes,sec:sub-task-2:model-classes}), which partition the
spaces of quantitative features \parencite[155]{Flach2012}, discretization may be
irrelevant.
