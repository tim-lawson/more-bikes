This report describes my approach to the `More Bikes' Kaggle competition, whose task is
to predict the number of available bikes at a set of rental stations in Valencia,
Spain.
I evaluated the performance of decision trees, gradient-boosted decision trees, and
stacked generalization with pre-trained linear models.
Generally, I found that gradient-boosted decision trees performed significantly better
than decision trees, and both performed significantly better than a baseline model that
predicted the arithmetic mean of the fraction of available bikes.
Stacked generalization with pre-trained linear models achieved comparable results to a
single gradient-boosted decision tree for all stations, but the latter achieved the
best result on the held-out test set.
